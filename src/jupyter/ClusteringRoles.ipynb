{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing data for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import itertools\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_to_file(folder_name, file_name, data):\n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir(folder_name)\n",
    "        print(\"Directory \" , folder_name ,  \" Created \") \n",
    "    except FileExistsError:\n",
    "        e = 1\n",
    "        #print(\"Directory \" , folder_name ,  \" already exists\")\n",
    "    data.to_csv(folder_name + \"/\" + file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_to_file_with_index(folder_name, file_name, data):\n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir(folder_name)\n",
    "        print(\"Directory \" , folder_name ,  \" Created \") \n",
    "    except FileExistsError:\n",
    "        e = 1\n",
    "        #print(\"Directory \" , folder_name ,  \" already exists\")\n",
    "    data.to_csv(folder_name + \"/\" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [(\"FrequencyOfUserPostsWithoutZeros\",\"std_post_frequency\"),\n",
    "            (\"FrequencyOfUserPostsWithoutZeros\",\"q3_post_frequency\"),\n",
    "            (\"NumberOfReceivedResponsesToUsersPostsWithoutZeros\",\"number_of_received_responses_to_users_posts_std\"),\n",
    "            (\"NumberOfReceivedResponsesToUsersPostsWithoutZeros\",\"number_of_received_responses_to_users_posts_max\"),\n",
    "            (\"NumberOfReceivedResponsesUnderUsersCommentsWithoutZeros\", \"number_of_received_responses_under_users_comments_q3\"),\n",
    "            (\"NumberOfReceivedResponsesUnderUsersCommentsWithoutZeros\",\"number_of_received_responses_under_users_comments_max\"),\n",
    "            (\"NumberOfWordsInOwnResponsesOfUsersPostsWithoutZeros\", \"number_of_words_in_own_responses_of_users_posts_q3\"),\n",
    "            (\"NumberOfWordsInResponsesOfUsersPostsWithoutZeros\",\"nnumber_of_words_in_responses_of_users_posts_median\"),\n",
    "            (\"SentimentOfUsersPostsWithoutZeros\",\"posts_sentiment_min\"),\n",
    "            (\"FrequencyOfUserCommentsWithoutZeros\", \"mean_comments_frequency\"),\n",
    "            (\"NumberOfWordsInUsersCommentsWithoutZeros\",\"number_of_words_in_users_comments_avg\"),\n",
    "            (\"NumberOfWordsInUsersPostsWithoutZeros\", \"number_of_words_in_users_posts_q3\"),\n",
    "            (\"NumberOfReceivedResponsesToUsersPostsWithoutZeros\", \"number_of_received_responses_to_users_posts_q3\"),\n",
    "            (\"NumberOfCommentsWrittenByUserUnderHisOwnPostsWithoutZeros\", \"number_of_comments_written_by_user_under_his_own_posts_q3\")\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_comments = datetime.date(2008, 12, 9)\n",
    "end_date_comments = datetime.date(2013,11, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"FrequencyOfUserCommentsWithoutZeros\" + \"/feature_\" + str(start_date_comments) + \".csv\")[[\"user_id\",\"mean_comments_frequency\"]]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_stats(start_date):\n",
    "    statistics_to_join = []\n",
    "    for feat in features:\n",
    "        (file_name, feature) = feat\n",
    "        statistics_to_join.append(pd.read_csv(file_name + \"/feature_\" + str(start_date) + \".csv\")[['user_id',feature]])\n",
    "    \n",
    "    merged_df = statistics_to_join[0]\n",
    "    for i in range(1, len(statistics_to_join)):\n",
    "        merged_df = pd.merge(merged_df, statistics_to_join[i],how='outer',on=['user_id'])\n",
    "    return merged_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster_data(start_date, end_date):\n",
    "    while start_date < end_date:\n",
    "        data = merge_stats(start_date)\n",
    "        #print(str(len(data)) + \" \" + str(start_date))\n",
    "        save_data_to_file(\"Cluster_Data\", \"cluster\" + str(start_date) + \".csv\", data)\n",
    "        start_date += timedelta(days=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_cluster_data(start_date_comments, end_date_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10170 2009-12-08\n",
    "#2733 2013-10-22\n",
    "start_date_clustering = datetime.date(2009, 12, 8)\n",
    "end_date_clustering = datetime.date(2013,10, 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose best k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate scores for different k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_custering(X):\n",
    "    columns=['k', 'score_mean', 'scored_std']\n",
    "    results = pd.DataFrame(columns=columns)\n",
    "    for k in range(3,11):\n",
    "        scores = []\n",
    "        for sample_num in range(0,5):\n",
    "            kmeans = KMeans(n_clusters=k).fit(X)\n",
    "            labels = kmeans.labels_\n",
    "            scores.append(metrics.calinski_harabasz_score(X, labels))\n",
    "        row = pd.DataFrame([[k, np.mean(scores), np.std(scores)]], columns=columns)\n",
    "        results = pd.concat([row, results], ignore_index=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_benchmark_clustering_data(start_date, end_date):\n",
    "    while start_date < end_date:\n",
    "        df = pd.read_csv(\"Cluster_Data\" + \"/cluster\" + str(start_date) + \".csv\").drop(columns =[\"user_id\"])\n",
    "        X = MinMaxScaler().fit_transform(df)\n",
    "        results = benchmark_custering(X)\n",
    "        save_data_to_file(\"Cluster_Benchmarks\", \"cluster_benchmark\" + str(start_date) + \".csv\", results)\n",
    "        print(\"Results for {} saved\".format(start_date))\n",
    "        start_date += timedelta(days=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_benchmark_clustering_data(start_date_clustering, end_date_clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate best k for given slot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def better(best, row):\n",
    "    score = 0\n",
    "    if (best[\"score_mean\"]  < row[\"score_mean\"]):\n",
    "        score+=1\n",
    "    if (best[\"score_mean\"] + best['scored_std']  < row[\"score_mean\"] + row['scored_std']):\n",
    "        score+=1\n",
    "    if (best[\"score_mean\"] - best['scored_std']  < row[\"score_mean\"] - row['scored_std']):\n",
    "        score+=1\n",
    "    if(score >= 2):\n",
    "        return row\n",
    "    else:\n",
    "        return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_k(df):\n",
    "    best_row = df.iloc[0]\n",
    "    for index, row in df.iterrows():\n",
    "        best_row = better(best_row, row)\n",
    "    return best_row[\"k\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best_k_for_slots(start_date, end_date):\n",
    "    columns=['date', 'k']\n",
    "    best_k_dataframe = pd.DataFrame(columns=columns)\n",
    "    while start_date < end_date:\n",
    "        df = pd.read_csv(\"Cluster_Benchmarks\" + \"/cluster_benchmark\" + str(start_date) + \".csv\")\n",
    "        k = choose_best_k(df)\n",
    "        row = pd.DataFrame([[start_date, k]], columns=columns)\n",
    "        best_k_dataframe = pd.concat([row, best_k_dataframe], ignore_index=True)\n",
    "        start_date += timedelta(days=14)\n",
    "    save_data_to_file(\"Cluster_Best_k\", \"cluster_best_k.csv\", best_k_dataframe)\n",
    "    print(\"Results for best_k saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_best_k_for_slots(start_date_clustering, end_date_clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate labeled data with best K number of clusters for given slot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    data_to_cluster = pd.read_csv(\"Cluster_Data\" + \"/cluster\" + row[\"date\"] + \".csv\")\n",
    "    data_without_id = data_to_cluster.drop(columns =[\"user_id\"])\n",
    "    data_to_cluster\n",
    "    X = MinMaxScaler().fit_transform(data_without_id)\n",
    "    kmeans = KMeans(n_clusters=int(row['k'])).fit(X)\n",
    "    labels_df = pd.DataFrame(kmeans.labels_, columns=[\"label\"])\n",
    "    labeled_users = pd.concat([data_to_cluster, labels_df], axis=1)\n",
    "    cluster_df = pd.DataFrame(kmeans.cluster_centers_, columns=data_without_id.columns.values)\n",
    "    \n",
    "    save_data_to_file(\"Labeled_users\", \"labeled_users\"+ row[\"date\"] +\".csv\", labeled_users)\n",
    "    save_data_to_file(\"Cluster_centers\", \"cluster_centers\"+ row[\"date\"] +\".csv\", cluster_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate statistics for clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"Labeled_users\" + \"/labeled_users\" + str(start_date_clustering) + \".csv\").drop(columns =[\"user_id\"])\n",
    "# features = df.drop(columns =[\"label\"]).columns.values\n",
    "# aggreagates = { feat : stats for feat in features }\n",
    "# features = df.drop(columns =[\"label\"]).columns.values\n",
    "# aggreagates = { feat : stats for feat in features }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_custer_statistics(start_date, end_date):\n",
    "    stats = [np.mean, np.std, np.min, np.max]\n",
    "    column_names = columns={'mean': 'mean','std': 'stddev', 'amin': 'min', 'amax': 'max'}\n",
    "    \n",
    "    #get sample feature names and create aggregats eg {'std_post_frequency': [np.mean, np.std, np.min, np.max]}\n",
    "    sample = pd.read_csv(\"Labeled_users\" + \"/labeled_users\" + str(start_date) + \".csv\").drop(columns =[\"user_id\"])\n",
    "    features = sample.drop(columns =[\"label\"]).columns.values\n",
    "    aggreagates = { feat : stats for feat in features }\n",
    "    \n",
    "    while start_date < end_date:\n",
    "        df = pd.read_csv(\"Labeled_users\" + \"/labeled_users\" + str(start_date) + \".csv\").drop(columns =[\"user_id\"])\n",
    "        \n",
    "        stats = (df.groupby(['label']).agg(aggreagates).rename(column_names))\n",
    "        stats_trans_df = stats.T\n",
    "        \n",
    "        save_data_to_file_with_index(\"ClustersStatistics\", \"clusters_stats\"+ str(start_date) +\".csv\", stats_trans_df)\n",
    "        start_date += timedelta(days=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_custer_statistics(start_date_clustering, end_date_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_stats(start_date, end_date):\n",
    "    while start_date < end_date:\n",
    "        print(\"Cluster for {}\".format(start_date))\n",
    "        display(pd.read_csv(\"ClustersStatistics\" + \"/clusters_stats\" + str(start_date) + \".csv\"))\n",
    "        start_date += timedelta(days=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_stats(start_date_clustering, end_date_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wnioski:\n",
    "    \n",
    "    Cluster for 2009-12-08:\n",
    "        \n",
    "    W pierwszym miesiacu mamy 3 klastry, widac wyraznie roznice w zachowaniu\n",
    "    Klaster 0 to typ osoby ktora postuje dosc czesto, jego posty są raczej pozytywne,\n",
    "    poniewaz minimalna wartosc sentymentu srednio przyjmuje wartosci neutralne\n",
    "    Dostaje duzo odpowiedzi na swoje posty\n",
    "    \n",
    "    \n",
    "    Dwa pozostale klastry to komentatorzy:\n",
    "        1: Roznia sie tym ze jeden pisze komentarze czesto jednak nie sa one bardzo dlugie\n",
    "        2: Drugi za to pisze komentarze rzadziej jednak są one dłuższe\n",
    "            \n",
    "                                                0           1          2\n",
    "            q3_post_frequency\tamax\t72.000000\t0.000000\t0.000000\n",
    "            number_of_received_responses_to_users_posts_max\tmean\t14.815977\t0.000000\t0.000000\n",
    "            number_of_received_responses_under_users_comme...\tmean\t0.000000\t1.011677\t0.416393\n",
    "            number_of_words_in_own_responses_of_users_post...\tmean\t0.000000\t0.000000\t0.000000\n",
    "            number_of_words_in_users_comments_avg\tmean\t29.459760\t32.454975\t139.903049\n",
    "            mean_comments_frequency\tmean\t1.656048\t14.616607\t2.638158\n",
    "            \n",
    "        \n",
    "    Cluster for 2009-12-22:\n",
    "        \n",
    "        W tym miesiacu mamy dwie role postujace 0 i 1 oraz jedna komentujaca 2\n",
    "        Rola 1 otrzymuje czesciej odpowiedzi do swoich postow w porownaniu z rola 0\n",
    "        1 nie udziela sie w dyskusji pod swoimi postami, 0 bierze udzial jednak niewielki\n",
    "        2 rola pisze jedynie komentarze, sa one dlugie nie pisze on bardzo czesto\n",
    "        0 pisze rowniez komentarze, dosc czesto\n",
    "        \n",
    "                                    0           1           2\n",
    "            \n",
    "        q3_post_frequency\tmean\t0.018265\t0.171450\t0.000000\n",
    "        number_of_received_responses_to_users_posts_max\tmean\t0.130266\t10.817837\t0.000000\n",
    "        number_of_received_responses_under_users_comments\tmean\t1.011674\t0.000000\t0.308072\n",
    "        number_of_words_in_own_responses_of_users_post\tmean\t0.020763\t0.000000\t0.000000\n",
    "        number_of_words_in_users_comments_avg\tmean\t36.079365\t31.883340\t150.996503\n",
    "        mean_comments_frequency\tmean\t7.327403\t1.375606\t1.576655\n",
    "        \n",
    "        \n",
    "Potencjalnie rola 2 z 2009-12-22 i 2 z 2009-12-08 to te same role \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_stats(start_date_clustering, end_date_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "from datetime import timedelta \n",
    "from textwrap import wrap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_comments = datetime.date(2008, 1, 1)\n",
    "end_date_comments = datetime.date(2013,7, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_table = pd.read_csv(\"FeatureTable_SALON.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_to_file(folder_name, file_name, data):\n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir(folder_name)\n",
    "        print(\"Directory \" , folder_name ,  \" Created \") \n",
    "    except FileExistsError:\n",
    "        e = 1\n",
    "        #print(\"Directory \" , folder_name ,  \" already exists\")\n",
    "    data.to_csv(folder_name + \"/\" + file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_stats(start_date):\n",
    "    statistics_to_join = []\n",
    "    for index, row in feature_table.iterrows():\n",
    "        folder = row[[\"NazwaFolderu\",\"NazwaCechy\"]][0]\n",
    "        feature_name = row[[\"NazwaFolderu\",\"NazwaCechy\"]][1]\n",
    "        statistics_to_join.append(pd.read_csv(folder + \"/feature_\" + str(start_date) + \".csv\")[['user_id',feature_name]])\n",
    "    \n",
    "    merged_df = statistics_to_join[0]\n",
    "    for i in range(1, len(statistics_to_join)):\n",
    "        merged_df = pd.merge(merged_df, statistics_to_join[i],how='outer',on=['user_id'])\n",
    "    return merged_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_active_users_data(start_date, end_date):\n",
    "    while start_date < end_date:\n",
    "        data = merge_stats(start_date)\n",
    "        print(str(start_date))\n",
    "        save_data_to_file(\"SALON_All_Data_In_Slots_Joined\", str(start_date) + \"_joined.csv\", data)\n",
    "        start_date += timedelta(days=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_active_users_data(start_date_comments, end_date_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_stats_for_general(start_date):\n",
    "    statistics_to_join = []\n",
    "    for index, row in feature_table.iterrows():\n",
    "        folder = row[[\"NazwaFolderu\",\"NazwaCechy\"]][0]\n",
    "        feature_name = row[[\"NazwaFolderu\",\"NazwaCechy\"]][1]\n",
    "        statistics_to_join.append(pd.read_csv(folder + \"/feature_\" + str(start_date) + \".csv\")[['user_id',feature_name]])\n",
    "    \n",
    "    merged_df = statistics_to_join[0]\n",
    "    for i in range(1, len(statistics_to_join)):\n",
    "        merged_df = pd.merge(merged_df, statistics_to_join[i],how='outer',on=['user_id'])\n",
    "    return merged_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster_data(start_date, end_date):\n",
    "    data = []\n",
    "    while start_date < end_date:\n",
    "        res = merge_stats_for_general(start_date)\n",
    "        data.append(len(res))\n",
    "        print(\"Data appended\")\n",
    "        print(len(res))\n",
    "        #print(str(len(data)) + \" \" + str(start_date))\n",
    "        #save_data_to_file(\"Cluster_Data\", \"cluster\" + str(start_date) + \".csv\", data)\n",
    "        start_date += timedelta(days=14)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = create_cluster_data(start_date_comments, end_date_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(data, color='orange', linewidth=4)\n",
    "plt.ylabel('All slots users activity')\n",
    "plt.title(\"SALON 24 users activity\", fontweight='bold')\n",
    "plt.savefig('salon24.png', dpi=300)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_zero_standard_deviation(features, feature_name):\n",
    "    data = features[feature_name]\n",
    "    non_zero_data = data.loc[data != 0.0]\n",
    "    std = non_zero_data.std()\n",
    "    if std is None:\n",
    "        std = 0\n",
    "    return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_standard_deviation(features, feature_name):\n",
    "    data = features[feature_name]\n",
    "    return data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precentage_of_non_zero_values(features, feature_name):\n",
    "    data = features[feature_name]\n",
    "    non_zero_data = data.loc[data != 0.0]\n",
    "    return len(non_zero_data.index) / len(data.index) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precentage_of_non_zero_values(result, feature_name):\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.rc('xtick',labelsize=16)\n",
    "    plt.rc('ytick',labelsize=16)\n",
    "    plt.plot(result, color='g', linewidth=3)\n",
    "    plt.title(f\"{feature_name}\", fontsize=20)\n",
    "    plt.ylabel('Percentage of non zero values'.format(feature_name), fontsize=20)\n",
    "    plt.xlabel('Slot number'.format(feature_name), fontsize=20)\n",
    "    plt.savefig(\"SalonFeatureAnalysisFigs/\" + \"PROCENTAGE_\" + feature_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_zero_standard_deviation(result, feature_name):\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.rc('xtick',labelsize=16)\n",
    "    plt.rc('ytick',labelsize=16)\n",
    "    plt.plot(result, color='b', linewidth=3)\n",
    "    plt.title(f\"{feature_name}\", fontsize=20)\n",
    "    plt.ylabel('Standard deviation'.format(feature_name), fontsize=20)\n",
    "    plt.xlabel('Slot number'.format(feature_name), fontsize=20)\n",
    "    plt.savefig(\"SalonFeatureAnalysisFigs/\" + \"STD_\" + feature_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_non_zero_standard_deviation(result, feature_name):\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.rc('xtick',labelsize=20)\n",
    "    plt.rc('ytick',labelsize=20)\n",
    "    plt.plot(result, color='r', linewidth=3)\n",
    "    \n",
    "    plt.title(\"\\n\".join(wrap(f\"None zero standard deviation of {feature_name}\", 60)), fontsize=50, fontweight='bold')\n",
    "    plt.ylabel('Standard deviation of none zero values'.format(feature_name), fontsize=40)\n",
    "    plt.xlabel('Slot number'.format(feature_name), fontsize=40)\n",
    "    plt.savefig(\"SalonFeatureAnalysisFigs/\" + \"NONZERO_STD_\" + feature_name, dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(res, feature_name):\n",
    "    plt.gcf().clear()\n",
    "#     binwidth = max(res) / 100\n",
    "#     bins=range(min(res), max(res) + 20, 20)\n",
    "#     plt.gca().set_xlim([0, max(res)])\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.rc('xtick',labelsize=20)\n",
    "    plt.rc('ytick',labelsize=20)\n",
    "    plt.yscale('log', nonposy='clip')\n",
    "    plt.hist(res.T, label=feature_name, histtype='bar', bins=100, alpha=0.5, edgecolor='black', facecolor='blue')\n",
    "    plt.legend(prop={'size': 16})\n",
    "    \n",
    "    plt.title(\"\\n\".join(wrap(f\"Histogram of {feature_name}\", 60)), fontsize=50, fontweight='bold')\n",
    "    plt.savefig(\"SalonFeatureAnalysisFigs/\" + \"HIST_\" + feature_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_charts_and_statistics(feature_table, start_date, end_date):\n",
    "    \n",
    "    feature_names = list(feature_table['NazwaCechy'])\n",
    "    \n",
    "    for f_name in feature_names:\n",
    "        print(f_name)\n",
    "        non_zero_stddev_res = []\n",
    "        zero_stddev_res = []\n",
    "        precentage_res = []\n",
    "        histogram_res = pd.DataFrame()\n",
    "        start = start_date\n",
    "        \n",
    "        while start < end_date:\n",
    "            features = pd.read_csv(\"SALON_All_Data_In_Slots_Joined/\" + str(start) + \"_joined.csv\")\n",
    "            \n",
    "            non_zero_stddev_res.append(non_zero_standard_deviation(features, f_name))\n",
    "            #zero_stddev_res.append(zero_standard_deviation(features, f_name))\n",
    "            #precentage_res.append(precentage_of_non_zero_values(features, f_name))\n",
    "            histogram_res = pd.concat([histogram_res, features[f_name]], ignore_index=True)\n",
    "            start += timedelta(days=14)\n",
    "            \n",
    "        plot_non_zero_standard_deviation(non_zero_stddev_res, f_name)\n",
    "#         plot_zero_standard_deviation(zero_stddev_res, f_name)\n",
    "#         plot_precentage_of_non_zero_values(precentage_res, f_name)\n",
    "        plot_histogram(histogram_res, f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_feature_charts_and_statistics(feature_table, start_date_comments, end_date_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stats_for_entire_data(feature_table, start_date, end_date):\n",
    "    results = pd.DataFrame()\n",
    "    while start_date < end_date:\n",
    "        features = pd.read_csv(\"SALON_All_Data_In_Slots_Joined/\" + str(start_date) + \"_joined.csv\")\n",
    "        results = pd.concat([results, features], ignore_index=True)\n",
    "        start_date += timedelta(days=14)\n",
    "    \n",
    "    feature_names = list(feature_table['NazwaCechy'])\n",
    "\n",
    "    for f_name in feature_names:\n",
    "        results\n",
    "        print(\"TYPE       | \" + f_name )\n",
    "        print(\"STD ZERO   | \" + str(zero_standard_deviation(results, f_name)))\n",
    "        print(\"STD NONZERO| \" + str(non_zero_standard_deviation(results, f_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_stats_for_entire_data(feature_table, start_date_comments, end_date_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"All_Data_In_Slots_Joined/\" + str('2010-01-05') + \"_joined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"posts_activity_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"posts_activity_time\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"All_Data_In_Slots_Joined/\" + str('2010-01-19') + \"_joined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"posts_activity_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[\"posts_activity_time\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
